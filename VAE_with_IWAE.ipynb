{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ''\n",
    "\n",
    "seed = None\n",
    "\n",
    "softmax = True\n",
    "\n",
    "#Data parameters\n",
    "batch_size = None\n",
    "num_workers = None\n",
    "train_percent = None\n",
    "\n",
    "#Model parameters\n",
    "num_sampling = None\n",
    "latent_dim = None\n",
    "encoder_hidden_dim = None\n",
    "decoder_hidden_dim = None\n",
    "\n",
    "x_sigma = None\n",
    "x_sigma_torch = torch.tensor(x_sigma).to(device)\n",
    "\n",
    "\n",
    "#Optimizer parameters\n",
    "learn_rate = None\n",
    "betas = None\n",
    "momentum = None\n",
    "\n",
    "checkpoint_file = 'checkpoints/vae_iwae'\n",
    "checkpoint_file_final = f'{checkpoint_file}_final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_csv(DATA_PATH, sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seed:\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "train_size = int(train_percent * df.shape[0])\n",
    "valiadte_size = df.shape[0] - train_size\n",
    "\n",
    "train_index = np.random.choice(np.arange(df.shape[0]),train_size, replace=False).tolist()\n",
    "validate_index = np.delete(np.arange(df.shape[0]),train_index).tolist()\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_index)\n",
    "validate_sampler = torch.utils.data.SubsetRandomSampler(validate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = torch.tensor(df.values).float()\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=train_size, num_workers=num_workers, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(data, batch_size=valiadte_size, num_workers=num_workers, sampler=validate_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from training import IWAETrainer\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions.log_normal import LogNormal\n",
    "from torch.distributions.gamma import Gamma\n",
    "import scipy\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, latent_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert in_channels > latent_dim, 'Bottleneck is required! in_channels should be larger than latent_dim'\n",
    "        \n",
    "        modules = []\n",
    "\n",
    "        for _ in range(hidden_dim):\n",
    "            modules +=[\n",
    "                nn.Linear(in_channels, in_channels, bias=False),\n",
    "                ]\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(*modules)\n",
    "        \n",
    "        self.encoder_mu = nn.Linear(in_channels, latent_dim)\n",
    "        self.encoder_var = nn.Linear(in_channels, latent_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear_layers(x)\n",
    "\n",
    "        mu = self.encoder_mu(out)\n",
    "        log_sigma = self.encoder_var(out)\n",
    "        \n",
    "        sigma = torch.exp(log_sigma)\n",
    "        \n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, out_channels, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        assert hidden_dim >= 1, 'Hidden dimension should not be smaller than 1'\n",
    "        assert out_channels > latent_dim, 'Bottleneck is required! in_channels should be larger than latent_dim'\n",
    "                \n",
    "        modules = []\n",
    "        if softmax:\n",
    "            modules = [nn.LogSoftmax(dim=2)]\n",
    "        \n",
    "\n",
    "        modules +=[\n",
    "            nn.Linear(latent_dim, out_channels, bias=False),\n",
    "            ]\n",
    "        \n",
    "        modules.append(nn.Tanh())\n",
    "        \n",
    "\n",
    "        for _ in range(hidden_dim-1):\n",
    "\n",
    "            modules +=[\n",
    "                nn.Linear(out_channels, out_channels, bias=False),\n",
    "                ]\n",
    "\n",
    "\n",
    "            modules.append(nn.Tanh())\n",
    "               \n",
    "        \n",
    "    \n",
    "        modules +=[\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            ]\n",
    "           \n",
    "        self.linear_layers = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, h):\n",
    "        \n",
    "        return self.linear_layers(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, features_encoder, features_decoder, in_size, z_dim, x_sigma):\n",
    "        \"\"\"\n",
    "        :param features_encoder: Instance of an encoder the extracts features\n",
    "        from an input.\n",
    "        :param features_decoder: Instance of a decoder that reconstructs an\n",
    "        input from it's features.\n",
    "        :param in_size: The size of one input (without batch dimension).\n",
    "        :param z_dim: The latent space dimension.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.features_encoder = features_encoder\n",
    "        self.features_decoder = features_decoder\n",
    "        self.z_dim = z_dim\n",
    "        self.x_sigma = x_sigma\n",
    "\n",
    "        \n",
    "    def encode(self, x):\n",
    "        mu, sigma = self.features_encoder(x)\n",
    "        u = Variable(sigma.data.new(sigma.size()).normal_())\n",
    "        z = mu + sigma * u\n",
    "        return z, mu, sigma, u\n",
    "\n",
    "    def decode(self, z, sample):\n",
    "        mu = self.features_decoder(z)\n",
    "        \n",
    "        if sample:\n",
    "            # Truncated Normal\n",
    "            if not softmax:\n",
    "                x = torch.tensor([ truncnorm.rvs(a=(-mean / x_sigma), b=(np.inf - mean) / x_sigma, loc=mean, scale=x_sigma) \n",
    "                              for mean in mu.detach().cpu().numpy().tolist()[0]]).to(device)\n",
    "            else:\n",
    "                x = torch.tensor([ truncnorm.rvs(a=(-mean / x_sigma), b=(np.inf - mean) / x_sigma, loc=mean, scale=x_sigma) \n",
    "                              for mean in mu.detach().cpu().numpy().tolist()[0][0]]).to(device)\n",
    "            \n",
    "            return x, mu\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "\n",
    "    def sample(self, n, to_numpy=False):\n",
    "        samples = []\n",
    "        device = next(self.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            if not softmax:\n",
    "                samples = [self.decode(torch.empty((1, self.z_dim)).normal_(mean=0, std=1).to(device), sample=True) for _ in range(n)]\n",
    "            else:\n",
    "                samples = [self.decode(torch.empty((1, 1, self.z_dim)).normal_(mean=0, std=1).to(device), sample=True) for _ in range(n)]\n",
    "\n",
    "        # Detach and move to CPU for display purposes\n",
    "        if not to_numpy:\n",
    "            mus = [s[1].detach().cpu() for s in samples]\n",
    "            samples = [s[0].detach().cpu() for s in samples]\n",
    "            \n",
    "        else:\n",
    "            mus = [s[1].detach().cpu().numpy() for s in samples]\n",
    "            samples = [s[0].detach().cpu().numpy() for s in samples]\n",
    "            \n",
    "        \n",
    "        return samples, mus\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, sigma, u = self.encode(x)\n",
    "        xr = self.decode(z, False)\n",
    "        \n",
    "        return z, mu, sigma, u, xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "data_dim = df.shape[1]\n",
    "\n",
    "encoder = LinearEncoder(in_channels=data_dim, latent_dim=latent_dim, hidden_dim=encoder_hidden_dim)\n",
    "decoder = LinearDecoder(latent_dim=latent_dim, out_channels=data_dim, hidden_dim=decoder_hidden_dim)\n",
    "\n",
    "vae = VAE(encoder, decoder, data_dim, latent_dim, x_sigma)\n",
    "vae_dp = DataParallel(vae).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learn_rate, betas=betas)\n",
    "#optimizer = optim.SGD(vae.parameters(), lr=learn_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iwae_loss(x, xr, z, mu, sigma, u, test):\n",
    "    # If both prior and posterior are normal, their constant terms can be canceled out\n",
    "    log_QzGx = torch.sum(-0.5*((z-mu)/sigma)**2 - torch.log(sigma), -1)    \n",
    "    log_Pz = torch.sum(-0.5*z**2, -1) \n",
    "    \n",
    "    #PxGz ~ Truncated Normal\n",
    "    log_PxGz = torch.sum(-0.5*((x-xr)/x_sigma)**2 + torch.tensor( np.log(2 / (np.sqrt(2* np.pi)))).float().to(device) - torch.log(torch.tensor(x_sigma).float()).to(device)\n",
    "                         - torch.log((0.5-0.5*torch.erf(-xr/ x_sigma_torch/ torch.tensor(np.sqrt(2)).float().to(device))) + torch.tensor(1e-8)), -1)\n",
    "        \n",
    "    log_weight = log_Pz + log_PxGz - log_QzGx\n",
    "    \n",
    "    if not test:    \n",
    "        #Normalization to prevent overflow\n",
    "        log_weight = log_weight - torch.max(log_weight, 0)[0]\n",
    "        weight = torch.exp(log_weight)\n",
    "        weight = weight / torch.sum(weight, 0)\n",
    "        weight = Variable(weight.data, requires_grad = False)\n",
    "        loss = -torch.mean(torch.sum(weight * (log_Pz + log_PxGz - log_QzGx), 0))\n",
    "    else:\n",
    "        #Standard Batch Solution for log-sum-exp numerical stability\n",
    "        #http://www.nowozin.net/sebastian/blog/streaming-log-sum-exp-computation.html\n",
    "        max_log_weight = torch.max(log_weight, 0)[0]\n",
    "        log_weight = log_weight - max_log_weight\n",
    "        weight = torch.exp(log_weight)\n",
    "        loss = -torch.mean(torch.log(torch.tensor(1/num_sampling)) + max_log_weight + torch.log(torch.sum(weight, 0)))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "def loss_fn(x, xr, z, mu, sigma, u, test):\n",
    "    return iwae_loss(x, xr, z, mu, sigma, u, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = IWAETrainer(vae_dp, loss_fn, optimizer, device, num_sampling, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN for REMOVING CHECKPOINT!!!!!\n",
    "if os.path.isfile(f'{checkpoint_file}.pt'):\n",
    "    os.remove(f'{checkpoint_file}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(f'{checkpoint_file_final}.pt'):\n",
    "    print(f'*** Loading final checkpoint file {checkpoint_file_final} instead of training')\n",
    "    checkpoint_file = checkpoint_file_final\n",
    "\n",
    "res = trainer.fit(train_loader, validation_loader,\n",
    "                  num_epochs=None, print_every=10,\n",
    "                  checkpoints=checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
